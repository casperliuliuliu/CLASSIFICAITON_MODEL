{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b5690d-751e-46fd-8779-c7418e276f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d375c9-3009-4f71-8a6b-5532030d960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441ace68-c932-4d6e-b452-8fd61c0026f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 10171\n",
      "Number of validation samples: 2543\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_dir = \"D:/P2023/DATA/glomer_cg\"\n",
    "\n",
    "# Create a single merged dataset\n",
    "merged_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "\n",
    "# Shuffle the merged dataset randomly\n",
    "random.seed(42)  # You can choose any random seed for reproducibility\n",
    "indices = list(range(len(merged_dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Define the split ratio (e.g., 80% for training and 20% for validation)\n",
    "split_ratio = 0.8  # You can adjust this ratio as needed\n",
    "\n",
    "# Calculate the split indices\n",
    "split_index = int(len(indices) * split_ratio)\n",
    "train_indices = indices[:split_index]\n",
    "val_indices = indices[split_index:]\n",
    "\n",
    "# Create data loaders for training and validation using the split indices\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(merged_dataset, batch_size=4, sampler=train_sampler, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(merged_dataset, batch_size=4, sampler=val_sampler, num_workers=0)\n",
    "\n",
    "# Example usage:\n",
    "print(f\"Number of training samples: {len(train_indices)}\")\n",
    "print(f\"Number of validation samples: {len(val_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665a7844-57b6-48d7-92f4-3d1b88148a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_datapoint = len(raw_datasets)\n",
    "\n",
    "image_datasets = {\n",
    "    \"train\": train_loader.dataset,\n",
    "    \"val\": val_loader.dataset\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=0)\n",
    "    for x in ['train', 'val']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad5b58c-0e0a-4c9c-aac1-7241fdf3a01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IGA', 'MGN']\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a6f963-35d0-49a8-b8cc-ebf26710e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdbd223-479b-4636-b159-654c1f623709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3fd180f-d314-4fc9-832a-17ffee02d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "# complete\n",
    "from datetime import datetime\n",
    "log_path =\"D:/P2023/LOG/inception_v3.txt\"\n",
    "# print and fprint at the same time\n",
    "def pprint(output = '\\n' , filename = log_path, show_time = False):\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "pprint(\"test\", show_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55f72dce-f29d-4f17-a6c5-b88aed145611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    best_recallmn = 0.0 # ***\n",
    "    best_recallig = 0.0 # ***\n",
    "    \n",
    "    best_precmn = 0.0 # ***\n",
    "    best_precig = 0.0 # ***\n",
    "    \n",
    "    best_f1mn = 0.0 # ***\n",
    "    best_f1ig = 0.0 # ***\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        pprint('Epoch {}/{}'.format(epoch, num_epochs - 1), show_time=True)\n",
    "        pprint('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            tp_positive = 0\n",
    "            fp_positive = 0\n",
    "            tn_negative = 0\n",
    "            fn_negative = 0\n",
    "            positive_other = 0\n",
    "            negative_other = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # MN -> positive\n",
    "                # iga -> negative\n",
    "                tp_positive += torch.sum((preds == 1) & (labels.data == 1))\n",
    "                fp_positive += torch.sum((preds == 1) & (labels.data == 0))\n",
    "                tn_negative += torch.sum((preds == 0) & (labels.data == 0))\n",
    "                fn_negative += torch.sum((preds == 0) & (labels.data == 1))\n",
    "                positive_other += torch.sum((preds == 2) & (labels.data == 1))\n",
    "                negative_other += torch.sum((preds == 2) & (labels.data == 0))\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            epoch_recallmn = tp_positive.double() / (tp_positive + fn_negative) # ***\n",
    "            epoch_recallig = tn_negative.double() / (tn_negative + fp_positive) # ***\n",
    "            \n",
    "            epoch_precmn = tp_positive.double() / (tp_positive + fp_positive) # ***\n",
    "            epoch_precig = tn_negative.double() / (tn_negative + fn_negative) # ***\n",
    "            \n",
    "            epoch_f1mn = (2 * epoch_recallmn * epoch_precmn) / (epoch_recallmn + epoch_precmn) # ***\n",
    "            epoch_f1ig = (2 * epoch_recallig * epoch_precig) / (epoch_recallig + epoch_precig) # ***\n",
    "            \n",
    "            # print('{} Loss: {:.4f} Acc: {:.4f} Recall_MGN: {:.4f} Recall_IGAN: {:.4f} Precision_MGN: {:.4f} Precision_IGAN: {:.4f} F1_MGN: {:.4f} F1_IGAN: {:.4f}'.format(\n",
    "            #     phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_recallig, epoch_precmn, epoch_precig, epoch_f1mn, epoch_f1ig)) # ***\n",
    "            pprint('{} Loss: {:.4f} Accuracy: {:.4f} \\n     Recall Precision F1_score OTHER\\n MGN: {:.4f} {:.4f} {:.4f} {}\\n IGAN:{:.4f} {:.4f} {:.4f} {}\\n'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_precmn, epoch_f1mn, positive_other, epoch_recallig, epoch_precig, epoch_f1ig, negative_other)) # ***\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            if phase == 'val' and epoch_recallmn > best_recallmn: # ***\n",
    "                best_recallmn = epoch_recallmn\n",
    "            if phase == 'val' and epoch_recallig > best_recallig: # ***\n",
    "                best_recallig = epoch_recallig  \n",
    "                \n",
    "            if phase == 'val' and epoch_precmn > best_precmn: # ***\n",
    "                best_precmn = epoch_precmn\n",
    "            if phase == 'val' and epoch_precig > best_precig: # ***\n",
    "                best_precig = epoch_precig    \n",
    "                \n",
    "            if phase == 'val' and epoch_f1mn > best_f1mn: # ***\n",
    "                best_f1mn = epoch_f1mn\n",
    "            if phase == 'val' and epoch_f1ig > best_f1ig: # ***\n",
    "                best_f1ig = epoch_f1ig   \n",
    "                \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    pprint('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    pprint('Best val Acc: {:.4f} \\n     Recall Precision F1_score\\n MGN: {:.4f} {:.4f} {:.4f}\\n IGAN:{:.4f} {:.4f} {:.4f}\\n'.format(\n",
    "                best_acc, best_recallmn, best_precmn, best_f1mn, best_recallig, best_precig, best_f1ig)) # ***\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa53919c-f0b0-4d83-a26c-f0d6755e1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mod(true_None, num_epoch):\n",
    "    model = models.inception_v3(weights=true_None)\n",
    "    model.aux_logits=False \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    # model_ft.aux_logits=False\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=num_epoch)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c1b8e5-b6a2-495b-a224-6d1a3295da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model at D:/P2023/WEIGHT/inception_50t.pt\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.5669 Accuracy: 0.6976 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.5112 0.6454 0.5705 0\n",
      " IGAN:0.8182 0.7211 0.7666 0\n",
      "\n",
      "val Loss: 0.4407 Accuracy: 0.8065 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.6805 0.7974 0.7343 0\n",
      " IGAN:0.8881 0.8111 0.8478 0\n",
      "\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.5085 Accuracy: 0.7525 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.6323 0.7069 0.6675 0\n",
      " IGAN:0.8303 0.7772 0.8029 0\n",
      "\n",
      "val Loss: 0.3835 Accuracy: 0.8400 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7936 0.7981 0.7959 0\n",
      " IGAN:0.8700 0.8669 0.8685 0\n",
      "\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.4738 Accuracy: 0.7773 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.6809 0.7333 0.7062 0\n",
      " IGAN:0.8397 0.8026 0.8207 0\n",
      "\n",
      "val Loss: 0.3457 Accuracy: 0.8593 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8171 0.8235 0.8203 0\n",
      " IGAN:0.8866 0.8822 0.8844 0\n",
      "\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.4373 Accuracy: 0.8021 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7208 0.7626 0.7411 0\n",
      " IGAN:0.8548 0.8255 0.8398 0\n",
      "\n",
      "val Loss: 0.2984 Accuracy: 0.8818 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8110 0.8788 0.8436 0\n",
      " IGAN:0.9276 0.8835 0.9050 0\n",
      "\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.4043 Accuracy: 0.8191 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7532 0.7791 0.7659 0\n",
      " IGAN:0.8618 0.8436 0.8526 0\n",
      "\n",
      "val Loss: 0.2621 Accuracy: 0.9004 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8803 0.8681 0.8742 0\n",
      " IGAN:0.9134 0.9218 0.9176 0\n",
      "\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.3770 Accuracy: 0.8317 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7760 0.7915 0.7837 0\n",
      " IGAN:0.8677 0.8568 0.8622 0\n",
      "\n",
      "val Loss: 0.2298 Accuracy: 0.9142 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8957 0.8870 0.8913 0\n",
      " IGAN:0.9261 0.9321 0.9291 0\n",
      "\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "val Loss: 0.2307 Accuracy: 0.9147 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.9516 0.8494 0.8976 0\n",
      " IGAN:0.8908 0.9660 0.9269 0\n",
      "\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.2988 Accuracy: 0.8765 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8331 0.8497 0.8413 0\n",
      " IGAN:0.9046 0.8933 0.8989 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_name = \"D:/P2023/WEIGHT/inception_50t.pt\"\n",
    "\n",
    "pprint(f\"Model at {weight_name}\")\n",
    "model = train_mod(True, 50)\n",
    "torch.save(model.state_dict(), weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0ee8a-a443-4a4f-880e-e5cfa08f7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_name = \"D:/P2023/WEIGHT/inception_50n.pt\"\n",
    "\n",
    "pprint(f\"Model at {weight_name}\")\n",
    "model = train_mod(None, 50)\n",
    "torch.save(model.state_dict(), weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429970b-05a7-40f8-b126-bdb2ce32708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_mod(True, 50)\n",
    "# torch.save(model.state_dict(), \"D:/P2023/WEIGHT/res18_50t.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
