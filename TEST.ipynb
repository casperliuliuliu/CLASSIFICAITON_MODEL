{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b5690d-751e-46fd-8779-c7418e276f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c777cbf-0119-464a-abaf-9036acdeb989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "log_path =\"D:/P2023/LOG/resnet18_50t_test2_0915.txt\"\n",
    "# print and fprint at the same time\n",
    "def pprint(output = '\\n' , filename = log_path, show_time = False):\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "pprint(\"test\", show_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d375c9-3009-4f71-8a6b-5532030d960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fa3ac2-9c02-416f-b537-92c43c467ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IGA': 7311, 'MGN': 993}\n",
      "993\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Set your data directory\n",
    "data_dir = \"D:/P2023/DATA/tvgh\"\n",
    "\n",
    "# Create the merged dataset\n",
    "merged_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "\n",
    "# Count the number of samples in each class\n",
    "class_counts = {}\n",
    "for _, label in merged_dataset.samples:\n",
    "    class_name = merged_dataset.classes[label]\n",
    "    class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "print(class_counts)\n",
    "# Determine the minimum number of samples among \"MGN\" and \"IGA\" classes\n",
    "min_class_count = min(class_counts[\"MGN\"], class_counts[\"IGA\"])\n",
    "print(min_class_count)\n",
    "# Create lists to hold the indices of samples to keep and to drop\n",
    "indices_to_keep = [min_class_count - ii -1 for ii in range(min_class_count*2)]\n",
    "\n",
    "merged_dataset.samples = [merged_dataset.samples[i] for i in indices_to_keep]\n",
    "merged_dataset.targets = [merged_dataset.targets[i] for i in indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7038e39-eaae-4ced-a404-322d53454ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 993, 1: 993})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(merged_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d091266-33ed-4a17-8164-1ef70e898080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1986\n",
      "    Root location: D:/P2023/DATA/tvgh\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5 0.5 0.5], std=[0.25 0.25 0.25])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(merged_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "print(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e116797b-38b3-4344-ad05-36df7b32c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IGA', 'MGN']\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = len(merged_dataset)\n",
    "class_names = merged_dataset.classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf3c5b3-ad4a-49fc-ba2c-f373473c6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mod(model):\n",
    "    since = time.time()\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    tp_positive = 0\n",
    "    fp_positive = 0\n",
    "    tn_negative = 0\n",
    "    fn_negative = 0\n",
    "    positive_other = 0\n",
    "    negative_other = 0\n",
    "    \n",
    "    # Iterate over data.\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        # MN -> positive\n",
    "        # iga -> negative\n",
    "        tp_positive += torch.sum((preds == 1) & (labels.data == 1))\n",
    "        fp_positive += torch.sum((preds == 1) & (labels.data == 0))\n",
    "        tn_negative += torch.sum((preds == 0) & (labels.data == 0))\n",
    "        fn_negative += torch.sum((preds == 0) & (labels.data == 1))\n",
    "        positive_other += torch.sum((preds == 2) & (labels.data == 1))\n",
    "        negative_other += torch.sum((preds == 2) & (labels.data == 0))\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "        epoch_recallmn = tp_positive.double() / (tp_positive + fn_negative) # ***\n",
    "        epoch_recallig = tn_negative.double() / (tn_negative + fp_positive) # ***\n",
    "                \n",
    "        epoch_precmn = tp_positive.double() / (tp_positive + fp_positive) # ***\n",
    "        epoch_precig = tn_negative.double() / (tn_negative + fn_negative) # ***\n",
    "        \n",
    "        epoch_f1mn = (2 * epoch_recallmn * epoch_precmn) / (epoch_recallmn + epoch_precmn) # ***\n",
    "        epoch_f1ig = (2 * epoch_recallig * epoch_precig) / (epoch_recallig + epoch_precig) # ***\n",
    "        \n",
    "        # print('{} Loss: {:.4f} Acc: {:.4f} Recall_MGN: {:.4f} Recall_IGAN: {:.4f} Precision_MGN: {:.4f} Precision_IGAN: {:.4f} F1_MGN: {:.4f} F1_IGAN: {:.4f}'.format(\n",
    "        #     phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_recallig, epoch_precmn, epoch_precig, epoch_f1mn, epoch_f1ig)) # ***\n",
    "        pprint('{} Loss: {:.4f} Accuracy: {:.4f} \\n     Recall Precision F1_score OTHER\\n MGN: {:.4f} {:.4f} {:.4f} {}\\n IGAN:{:.4f} {:.4f} {:.4f} {}\\n'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_precmn, epoch_f1mn, positive_other, epoch_recallig, epoch_precig, epoch_f1ig, negative_other)) # ***\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    pprint('Testing complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550af11-8fc9-4b1e-9a4c-3b5ff8a0084d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def test_mod(PATH):\n",
    "    model = models.resnet18(weights=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # # Step 1: Load the model and state dictionary from the .pt file\n",
    "    # checkpoint = torch.load(PATH)  # Load the state dictionary from the file\n",
    "    \n",
    "    # # Assuming your model is named 'model' and the state dictionary key is 'state_dict'\n",
    "    # model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # # Step 2: Serialize the state dictionary into bytes\n",
    "    # buffer = io.BytesIO()\n",
    "    # torch.save(checkpoint, buffer)\n",
    "\n",
    "    # buffer.seek(0)  # Make sure to reset the buffer position to the beginning\n",
    "    # checkpoint = torch.load(buffer)\n",
    "    # model.load_state_dict(checkpoint)\n",
    "    # # print(checkpoint)\n",
    "    # # Step 3: The state dictionary is now stored in 'buffer' as bytes and can be used as needed\n",
    "    model.eval()\n",
    "    test_mod(model)\n",
    "\n",
    "\n",
    "path = \"D:/P2023/WEIGHT/raw_data_training/res18_50t.pt\"\n",
    "test_mod(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
