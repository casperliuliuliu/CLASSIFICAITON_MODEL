{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b5690d-751e-46fd-8779-c7418e276f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c777cbf-0119-464a-abaf-9036acdeb989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "log_path =\"D:/P2023/LOG/resnet18_50t_test2_0915.txt\"\n",
    "# print and fprint at the same time\n",
    "def pprint(output = '\\n' , filename = log_path, show_time = False):\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "pprint(\"test\", show_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9d375c9-3009-4f71-8a6b-5532030d960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7fa3ac2-9c02-416f-b537-92c43c467ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IGA': 7311, 'MGN': 993}\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Set your data directory\n",
    "data_dir = \"D:/P2023/DATA/tvgh\"\n",
    "\n",
    "# Create the merged dataset\n",
    "merged_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "\n",
    "# Count the number of samples in each class\n",
    "class_counts = {}\n",
    "for _, label in merged_dataset.samples:\n",
    "    class_name = merged_dataset.classes[label]\n",
    "    class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "print(class_counts)\n",
    "\n",
    "# This part of code is to select maximum same amoutnt of data\n",
    "# Determine the minimum number of samples among \"MGN\" and \"IGA\" classes\n",
    "min_class_count = min(class_counts[\"MGN\"], class_counts[\"IGA\"])\n",
    "min_class_count = 200\n",
    "print(min_class_count)\n",
    "# Create lists to hold the indices of samples to keep and to drop\n",
    "indices_to_keep = [min_class_count - ii -1 for ii in range(min_class_count*2)]\n",
    "\n",
    "merged_dataset.samples = [merged_dataset.samples[i] for i in indices_to_keep]\n",
    "merged_dataset.targets = [merged_dataset.targets[i] for i in indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7038e39-eaae-4ced-a404-322d53454ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 200, 1: 200})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(merged_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d091266-33ed-4a17-8164-1ef70e898080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 400\n",
      "    Root location: D:/P2023/DATA/tvgh\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5 0.5 0.5], std=[0.25 0.25 0.25])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(merged_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "print(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e116797b-38b3-4344-ad05-36df7b32c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IGA', 'MGN']\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = len(merged_dataset)\n",
    "class_names = merged_dataset.classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "baf3c5b3-ad4a-49fc-ba2c-f373473c6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_mod(model, criterion, class_names):\n",
    "    since = time.time()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    num_class = len(class_names)\n",
    "    tp_positive = 0\n",
    "    fp_positive = 0\n",
    "    tn_negative = 0\n",
    "    fn_negative = 0\n",
    "    # positive_other = 0\n",
    "    # negative_other = 0\n",
    "    confus = torch.zeros(num_class, num_class,dtype=int)\n",
    "    # Iterate over data.\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # print(labels)\n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        for ii in range(len(preds)):\n",
    "            confus[labels.data[ii]][preds[ii]]+=1\n",
    "        \n",
    "        # MN -> positive\n",
    "        # iga -> negative\n",
    "        tp_positive += torch.sum((preds == 1) & (labels.data == 1))\n",
    "        fp_positive += torch.sum((preds == 1) & (labels.data == 0))\n",
    "        tn_negative += torch.sum((preds == 0) & (labels.data == 0))\n",
    "        fn_negative += torch.sum((preds == 0) & (labels.data == 1))\n",
    "        # positive_other += torch.sum((preds == 2) & (labels.data == 1))\n",
    "        # negative_other += torch.sum((preds == 2) & (labels.data == 0))\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes\n",
    "        \n",
    "        epoch_recallmn = tp_positive.double() / (tp_positive + fn_negative) # ***\n",
    "        epoch_recallig = tn_negative.double() / (tn_negative + fp_positive) # ***\n",
    "                \n",
    "        epoch_precmn = tp_positive.double() / (tp_positive + fp_positive) # ***\n",
    "        epoch_precig = tn_negative.double() / (tn_negative + fn_negative) # ***\n",
    "        \n",
    "        epoch_f1mn = (2 * epoch_recallmn * epoch_precmn) / (epoch_recallmn + epoch_precmn) # ***\n",
    "        epoch_f1ig = (2 * epoch_recallig * epoch_precig) / (epoch_recallig + epoch_precig) # ***\n",
    "        \n",
    "        # print('{} Loss: {:.4f} Acc: {:.4f} Recall_MGN: {:.4f} Recall_IGAN: {:.4f} Precision_MGN: {:.4f} Precision_IGAN: {:.4f} F1_MGN: {:.4f} F1_IGAN: {:.4f}'.format(\n",
    "        #     phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_recallig, epoch_precmn, epoch_precig, epoch_f1mn, epoch_f1ig)) # ***\n",
    "    print(confus)\n",
    "    print(confus.sum())\n",
    "    pprint('Loss: {:.4f} Accuracy: {:.4f} \\n     Recall Precision F1_score \\n MGN: {:.4f} {:.4f} {:.4f} \\n IGAN:{:.4f} {:.4f} {:.4f} \\n'.format(\n",
    "            epoch_loss, epoch_acc, epoch_recallmn, epoch_precmn, epoch_f1mn, epoch_recallig, epoch_precig, epoch_f1ig)) # ***\n",
    "    for ii in range(num_class):\n",
    "\n",
    "    # pprint(' Loss: {:.4f} Accuracy: {:.4f}\\n'.format(\n",
    "    #              epoch_loss, epoch_acc)) # ***\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    pprint('Testing complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "100d139b-e3f2-40c4-9332-73315dea79c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[167,  33],\n",
      "        [194,   6]])\n",
      "tensor(400)\n",
      "Loss: 0.7803 Accuracy: 0.4325 \n",
      "     Recall Precision F1_score \n",
      " MGN: 0.0300 0.1538 0.0502 \n",
      " IGAN:0.8350 0.4626 0.5954 \n",
      "\n",
      "Testing complete in 0m 6s\n"
     ]
    }
   ],
   "source": [
    "def testing(PATH, class_names):\n",
    "    model = models.resnet152(weights=None)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 5)\n",
    "    state_dict = torch.load(PATH)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    # step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    val_mod(model,criterion, class_names)\n",
    "    \n",
    "path = \"D:/P2023/WEIGHT/raw_data_training/res152_50t_class5.pt\"\n",
    "testing(path,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6550af11-8fc9-4b1e-9a4c-3b5ff8a0084d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 63\u001b[0m\n\u001b[0;32m     59\u001b[0m     test_mod(model)\n\u001b[0;32m     62\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/P2023/WEIGHT/raw_data_training/res18_50t.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 63\u001b[0m \u001b[43mtest_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 59\u001b[0m, in \u001b[0;36mtest_mod\u001b[1;34m(PATH)\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# state_dict = torch.load(PATH)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(state_dict, strict=False)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# # model = model.to(device)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# # # print(model)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mtest_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 59\u001b[0m, in \u001b[0;36mtest_mod\u001b[1;34m(PATH)\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# state_dict = torch.load(PATH)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(state_dict, strict=False)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# # model = model.to(device)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# # # print(model)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mtest_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: test_mod at line 59 (498 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[16], line 59\u001b[0m, in \u001b[0;36mtest_mod\u001b[1;34m(PATH)\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# state_dict = torch.load(PATH)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(state_dict, strict=False)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# # model = model.to(device)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# # # print(model)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mtest_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m, in \u001b[0;36mtest_mod\u001b[1;34m(PATH)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_mod\u001b[39m(PATH):\n\u001b[1;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     num_ftrs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[0;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\resnet.py:705\u001b[0m, in \u001b[0;36mresnet18\u001b[1;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"ResNet-18 from `Deep Residual Learning for Image Recognition <https://arxiv.org/pdf/1512.03385.pdf>`__.\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m    :members:\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m weights \u001b[38;5;241m=\u001b[39m ResNet18_Weights\u001b[38;5;241m.\u001b[39mverify(weights)\n\u001b[1;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _resnet(BasicBlock, [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m], weights, progress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\resnet.py:298\u001b[0m, in \u001b[0;36m_resnet\u001b[1;34m(block, layers, weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     _ovewrite_named_param(kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(weights\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m--> 298\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet(block, layers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(weights\u001b[38;5;241m.\u001b[39mget_state_dict(progress\u001b[38;5;241m=\u001b[39mprogress))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\resnet.py:210\u001b[0m, in \u001b[0;36mResNet.__init__\u001b[1;34m(self, block, layers, num_classes, zero_init_residual, groups, width_per_group, replace_stride_with_dilation, norm_layer)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules():\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mConv2d):\n\u001b[1;32m--> 210\u001b[0m         \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_normal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfan_out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonlinearity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, (nn\u001b[38;5;241m.\u001b[39mBatchNorm2d, nn\u001b[38;5;241m.\u001b[39mGroupNorm)):\n\u001b[0;32m    212\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mconstant_(m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\init.py:451\u001b[0m, in \u001b[0;36mkaiming_normal_\u001b[1;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[0;32m    449\u001b[0m std \u001b[38;5;241m=\u001b[39m gain \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(fan)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test(PATH):\n",
    "    model = models.resnet18(weights=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # # Step 1: Load the model and state dictionary from the .pt file\n",
    "    # checkpoint = torch.load(PATH)  # Load the state dictionary from the file\n",
    "    \n",
    "    # # Assuming your model is named 'model' and the state dictionary key is 'state_dict'\n",
    "    # model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # # Step 2: Serialize the state dictionary into bytes\n",
    "    # buffer = io.BytesIO()\n",
    "    # torch.save(checkpoint, buffer)\n",
    "\n",
    "    # buffer.seek(0)  # Make sure to reset the buffer position to the beginning\n",
    "    # checkpoint = torch.load(buffer)\n",
    "    # model.load_state_dict(checkpoint)\n",
    "    # # print(checkpoint)\n",
    "    # # Step 3: The state dictionary is now stored in 'buffer' as bytes and can be used as needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    # state_dict = torch.load(PATH)\n",
    "    # model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # # print(state_dict)\n",
    "    # # print(model.state_dict)\n",
    "    # # print(torch.load(PATH))\n",
    "    # # # b = json.dumps(torch.load(PATH), indent=2).encode('utf-8')\n",
    "    # # res_bytes = json.dumps(torch.load(PATH)).encode('utf-8')\n",
    "    # # buffer = io.BytesIO(b)\n",
    "    \n",
    "    # # Serialize and write data to the buffer\n",
    "    # # torch.save(, buffer)\n",
    "    \n",
    "    # # Seek back to the beginning of the buffer\n",
    "    # # buffer.seek(0)\n",
    "    \n",
    "    # # Load data from the buffer\n",
    "    # # loaded_data = torch.load(buffer)\n",
    "    \n",
    "    # # model.load_state_dict(loaded_data)\n",
    "    \n",
    "    # # # stream = io.BytesIO(a.tobytes())\n",
    "    # # model = model.to(device)\n",
    "    # # # print(model)\n",
    "    test_mod(model)\n",
    "\n",
    "\n",
    "path = \"D:/P2023/WEIGHT/raw_data_training/res18_50t.pt\"\n",
    "test_mod(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55f72dce-f29d-4f17-a6c5-b88aed145611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    best_recallmn = 0.0 # ***\n",
    "    best_recallig = 0.0 # ***\n",
    "    \n",
    "    best_precmn = 0.0 # ***\n",
    "    best_precig = 0.0 # ***\n",
    "    \n",
    "    best_f1mn = 0.0 # ***\n",
    "    best_f1ig = 0.0 # ***\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        pprint('Epoch {}/{}'.format(epoch, num_epochs - 1), show_time=True)\n",
    "        pprint('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            tp_positive = 0\n",
    "            fp_positive = 0\n",
    "            tn_negative = 0\n",
    "            fn_negative = 0\n",
    "            positive_other = 0\n",
    "            negative_other = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # MN -> positive\n",
    "                # iga -> negative\n",
    "                tp_positive += torch.sum((preds == 1) & (labels.data == 1))\n",
    "                fp_positive += torch.sum((preds == 1) & (labels.data == 0))\n",
    "                tn_negative += torch.sum((preds == 0) & (labels.data == 0))\n",
    "                fn_negative += torch.sum((preds == 0) & (labels.data == 1))\n",
    "                positive_other += torch.sum((preds == 2) & (labels.data == 1))\n",
    "                negative_other += torch.sum((preds == 2) & (labels.data == 0))\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            epoch_recallmn = tp_positive.double() / (tp_positive + fn_negative) # ***\n",
    "            epoch_recallig = tn_negative.double() / (tn_negative + fp_positive) # ***\n",
    "            \n",
    "            epoch_precmn = tp_positive.double() / (tp_positive + fp_positive) # ***\n",
    "            epoch_precig = tn_negative.double() / (tn_negative + fn_negative) # ***\n",
    "            \n",
    "            epoch_f1mn = (2 * epoch_recallmn * epoch_precmn) / (epoch_recallmn + epoch_precmn) # ***\n",
    "            epoch_f1ig = (2 * epoch_recallig * epoch_precig) / (epoch_recallig + epoch_precig) # ***\n",
    "            \n",
    "            # print('{} Loss: {:.4f} Acc: {:.4f} Recall_MGN: {:.4f} Recall_IGAN: {:.4f} Precision_MGN: {:.4f} Precision_IGAN: {:.4f} F1_MGN: {:.4f} F1_IGAN: {:.4f}'.format(\n",
    "            #     phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_recallig, epoch_precmn, epoch_precig, epoch_f1mn, epoch_f1ig)) # ***\n",
    "            pprint('{} Loss: {:.4f} Accuracy: {:.4f} \\n     Recall Precision F1_score OTHER\\n MGN: {:.4f} {:.4f} {:.4f} {}\\n IGAN:{:.4f} {:.4f} {:.4f} {}\\n'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_precmn, epoch_f1mn, positive_other, epoch_recallig, epoch_precig, epoch_f1ig, negative_other)) # ***\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            if phase == 'val' and epoch_recallmn > best_recallmn: # ***\n",
    "                best_recallmn = epoch_recallmn\n",
    "            if phase == 'val' and epoch_recallig > best_recallig: # ***\n",
    "                best_recallig = epoch_recallig  \n",
    "                \n",
    "            if phase == 'val' and epoch_precmn > best_precmn: # ***\n",
    "                best_precmn = epoch_precmn\n",
    "            if phase == 'val' and epoch_precig > best_precig: # ***\n",
    "                best_precig = epoch_precig    \n",
    "                \n",
    "            if phase == 'val' and epoch_f1mn > best_f1mn: # ***\n",
    "                best_f1mn = epoch_f1mn\n",
    "            if phase == 'val' and epoch_f1ig > best_f1ig: # ***\n",
    "                best_f1ig = epoch_f1ig   \n",
    "                \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    pprint('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    pprint('Best val Acc: {:.4f} \\n     Recall Precision F1_score\\n MGN: {:.4f} {:.4f} {:.4f}\\n IGAN:{:.4f} {:.4f} {:.4f}\\n'.format(\n",
    "                best_acc, best_recallmn, best_precmn, best_f1mn, best_recallig, best_precig, best_f1ig)) # ***\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa53919c-f0b0-4d83-a26c-f0d6755e1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mod(true_None, num_epoch):\n",
    "    model = models.resnet101(weights=true_None)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 3)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=num_epoch)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c1b8e5-b6a2-495b-a224-6d1a3295da06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model at D:/P2023/WEIGHT/res18_50t_other.pt\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.5590 Accuracy: 0.7117 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.5608 0.6558 0.6046 1\n",
      " IGAN:0.8095 0.7401 0.7732 1\n",
      "\n",
      "val Loss: 0.4136 Accuracy: 0.8141 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.6849 0.8126 0.7433 0\n",
      " IGAN:0.8978 0.8149 0.8543 0\n",
      "\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.4955 Accuracy: 0.7634 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.6533 0.7189 0.6846 0\n",
      " IGAN:0.8347 0.7881 0.8107 0\n",
      "\n",
      "val Loss: 0.3705 Accuracy: 0.8355 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8575 0.7564 0.8038 0\n",
      " IGAN:0.8212 0.8990 0.8583 0\n",
      "\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.4691 Accuracy: 0.7770 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.6777 0.7343 0.7049 0\n",
      " IGAN:0.8413 0.8013 0.8208 0\n",
      "\n",
      "val Loss: 0.3018 Accuracy: 0.8762 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8129 0.8640 0.8377 0\n",
      " IGAN:0.9172 0.8833 0.8999 0\n",
      "\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.4430 Accuracy: 0.7932 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7094 0.7507 0.7294 0\n",
      " IGAN:0.8475 0.8183 0.8327 0\n",
      "\n",
      "val Loss: 0.2757 Accuracy: 0.8828 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.8090 0.8829 0.8444 0\n",
      " IGAN:0.9306 0.8827 0.9060 0\n",
      "\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.4169 Accuracy: 0.8123 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7372 0.7744 0.7553 0\n",
      " IGAN:0.8610 0.8350 0.8478 0\n",
      "\n",
      "val Loss: 0.2381 Accuracy: 0.9021 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.9057 0.8539 0.8791 0\n",
      " IGAN:0.8997 0.9365 0.9177 0\n",
      "\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.3988 Accuracy: 0.8194 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7460 0.7840 0.7645 0\n",
      " IGAN:0.8669 0.8406 0.8536 0\n",
      "\n",
      "val Loss: 0.2144 Accuracy: 0.9154 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.9378 0.8598 0.8971 0\n",
      " IGAN:0.9010 0.9572 0.9283 0\n",
      "\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.3693 Accuracy: 0.8363 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.7730 0.8031 0.7878 0\n",
      " IGAN:0.8773 0.8565 0.8668 0\n",
      "\n",
      "val Loss: 0.1762 Accuracy: 0.9372 \n",
      "     Recall Precision F1_score OTHER\n",
      " MGN: 0.9129 0.9261 0.9195 0\n",
      " IGAN:0.9528 0.9442 0.9485 0\n",
      "\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "weight_name = \"D:/P2023/WEIGHT/res101_50t_other.pt\"\n",
    "\n",
    "pprint(f\"Model at {weight_name}\")\n",
    "model = train_mod(True, 50)\n",
    "torch.save(model.state_dict(), weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0ee8a-a443-4a4f-880e-e5cfa08f7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_mod(None, 50)\n",
    "# torch.save(model.state_dict(), \"D:/P2023/WEIGHT/res18_50n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429970b-05a7-40f8-b126-bdb2ce32708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_mod(True, 50)\n",
    "# torch.save(model.state_dict(), \"D:/P2023/WEIGHT/res18_50t.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
