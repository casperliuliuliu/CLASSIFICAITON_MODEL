{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b5690d-751e-46fd-8779-c7418e276f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d375c9-3009-4f71-8a6b-5532030d960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441ace68-c932-4d6e-b452-8fd61c0026f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"E:/casper/raw_data_training\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad5b58c-0e0a-4c9c-aac1-7241fdf3a01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IgA', 'MN']\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a6f963-35d0-49a8-b8cc-ebf26710e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdbd223-479b-4636-b159-654c1f623709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e85f1e6-9b24-4cf2-987b-3bb4faf133ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ori(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # print(labels.data)\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f72dce-f29d-4f17-a6c5-b88aed145611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    best_recallmn = 0.0 # ***\n",
    "    best_recallig = 0.0 # ***\n",
    "    \n",
    "    best_precmn = 0.0 # ***\n",
    "    best_precig = 0.0 # ***\n",
    "    \n",
    "    best_f1mn = 0.0 # ***\n",
    "    best_f1ig = 0.0 # ***\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            tp_positive = 0\n",
    "            fp_positive = 0\n",
    "            tn_negative = 0\n",
    "            fn_negative = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # MN -> positive\n",
    "                # iga -> negative\n",
    "                tp_positive += torch.sum((preds == 1) & (labels.data == 1))\n",
    "                fp_positive += torch.sum((preds == 1) & (labels.data == 0))\n",
    "                tn_negative += torch.sum((preds == 0) & (labels.data == 0))\n",
    "                fn_negative += torch.sum((preds == 0) & (labels.data == 1))\n",
    "                    \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            epoch_recallmn = tp_positive.double() / (tp_positive + fn_negative) # ***\n",
    "            epoch_recallig = tn_negative.double() / (tn_negative + fp_positive) # ***\n",
    "            \n",
    "            epoch_precmn = tp_positive.double() / (tp_positive + fp_positive) # ***\n",
    "            epoch_precig = tn_negative.double() / (tn_negative + fn_negative) # ***\n",
    "            \n",
    "            epoch_f1mn = (2 * epoch_recallmn * epoch_precmn) / (epoch_recallmn + epoch_precmn) # ***\n",
    "            epoch_f1ig = (2 * epoch_recallig * epoch_precig) / (epoch_recallig + epoch_precig) # ***\n",
    "            \n",
    "            # print('{} Loss: {:.4f} Acc: {:.4f} Recall_MGN: {:.4f} Recall_IGAN: {:.4f} Precision_MGN: {:.4f} Precision_IGAN: {:.4f} F1_MGN: {:.4f} F1_IGAN: {:.4f}'.format(\n",
    "            #     phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_recallig, epoch_precmn, epoch_precig, epoch_f1mn, epoch_f1ig)) # ***\n",
    "            print('{} Loss: {:.4f} Accuracy: {:.4f} \\n     Recall Precision F1_score\\n MGN: {:.4f} {:.4f} {:.4f}\\n IGAN:{:.4f} {:.4f} {:.4f}\\n'.format(\n",
    "                    phase, epoch_loss, epoch_acc, epoch_recallmn, epoch_precmn, epoch_f1mn, epoch_recallig, epoch_precig, epoch_f1ig)) # ***\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            if phase == 'val' and epoch_recallmn > best_recallmn: # ***\n",
    "                best_recallmn = epoch_recallmn\n",
    "            if phase == 'val' and epoch_recallig > best_recallig: # ***\n",
    "                best_recallig = epoch_recallig  \n",
    "                \n",
    "            if phase == 'val' and epoch_precmn > best_precmn: # ***\n",
    "                best_precmn = epoch_precmn\n",
    "            if phase == 'val' and epoch_precig > best_precig: # ***\n",
    "                best_precig = epoch_precig    \n",
    "                \n",
    "            if phase == 'val' and epoch_f1mn > best_f1mn: # ***\n",
    "                best_f1mn = epoch_f1mn\n",
    "            if phase == 'val' and epoch_f1ig > best_f1ig: # ***\n",
    "                best_f1ig = epoch_f1ig   \n",
    "                \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f} \\n     Recall Precision F1_score\\n MGN: {:.4f} {:.4f} {:.4f}\\n IGAN:{:.4f} {:.4f} {:.4f}\\n'.format(\n",
    "                best_acc, best_recallmn, best_precmn, best_f1mn, best_recallig, best_precig, best_f1ig)) # ***\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "471db232-b593-45bf-9f0a-a6c4cd5de1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model3(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    # Variables to keep track of true positives, false positives, true negatives, false negatives\n",
    "    tp_positive = 0\n",
    "    fp_positive = 0\n",
    "    tn_negative = 0\n",
    "    fn_negative = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Calculate precision for positive label and negative label\n",
    "                    if phase == 'val':\n",
    "                        tp_positive += torch.sum((preds == 1) & (labels.data == 1))\n",
    "                        fp_positive += torch.sum((preds == 1) & (labels.data == 0))\n",
    "                        tn_negative += torch.sum((preds == 0) & (labels.data == 0))\n",
    "                        fn_negative += torch.sum((preds == 0) & (labels.data == 1))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # Calculate precision for positive label and negative label\n",
    "    precision_positive = tp_positive.double() / (tp_positive + fp_positive)\n",
    "    precision_negative = tn_negative.double() / (tn_negative + fn_negative)\n",
    "    print('Precision (Positive Label): {:.4f}'.format(precision_positive))\n",
    "    print('Precision (Negative Label): {:.4f}'.format(precision_negative))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa53919c-f0b0-4d83-a26c-f0d6755e1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mod(true_None, num_epoch):\n",
    "    model = models.resnet18(weights=true_None)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=num_epoch)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d0758ed-f24f-481f-b765-97bce6334480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.6144 Accuracy: 0.6535 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.3290 0.5534 0.4127\n",
      " IGAN:0.8441 0.6817 0.7542\n",
      "\n",
      "val Loss: 0.7011 Accuracy: 0.5279 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.2688 0.7562 0.3967\n",
      " IGAN:0.8816 0.4690 0.6123\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.5820 Accuracy: 0.6793 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4518 0.5865 0.5104\n",
      " IGAN:0.8129 0.7163 0.7615\n",
      "\n",
      "val Loss: 0.7207 Accuracy: 0.5627 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.3128 0.8164 0.4523\n",
      " IGAN:0.9039 0.4907 0.6361\n",
      "\n",
      "\n",
      "Training complete in 3m 53s\n",
      "Best val Acc: 0.5627 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.3128 0.8164 0.4523\n",
      " IGAN:0.9039 0.4907 0.6361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_mod(None, 2)\n",
    "torch.save(model.state_dict(), \"res18_2n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63919b9d-d8dc-49d1-b03a-96bab1e9b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.6209 Accuracy: 0.6544 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.2996 0.5620 0.3908\n",
      " IGAN:0.8629 0.6772 0.7588\n",
      "\n",
      "val Loss: 0.7132 Accuracy: 0.5540 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.3794 0.7139 0.4955\n",
      " IGAN:0.7925 0.4833 0.6004\n",
      "\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.5874 Accuracy: 0.6815 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4361 0.5951 0.5034\n",
      " IGAN:0.8257 0.7137 0.7656\n",
      "\n",
      "val Loss: 0.6802 Accuracy: 0.6041 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8543 0.6126 0.7135\n",
      " IGAN:0.2624 0.5688 0.3592\n",
      "\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.5649 Accuracy: 0.7022 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4947 0.6228 0.5514\n",
      " IGAN:0.8240 0.7352 0.7771\n",
      "\n",
      "val Loss: 0.7038 Accuracy: 0.6222 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5327 0.7400 0.6194\n",
      " IGAN:0.7444 0.5385 0.6249\n",
      "\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.5584 Accuracy: 0.7046 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4996 0.6264 0.5559\n",
      " IGAN:0.8250 0.7373 0.7787\n",
      "\n",
      "val Loss: 0.6115 Accuracy: 0.6882 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6269 0.7896 0.6989\n",
      " IGAN:0.7719 0.6024 0.6767\n",
      "\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.5439 Accuracy: 0.7152 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5300 0.6389 0.5793\n",
      " IGAN:0.8240 0.7491 0.7848\n",
      "\n",
      "val Loss: 0.6052 Accuracy: 0.6780 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8467 0.6767 0.7522\n",
      " IGAN:0.4477 0.6815 0.5404\n",
      "\n",
      "\n",
      "Training complete in 9m 36s\n",
      "Best val Acc: 0.6882 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8543 0.7896 0.7522\n",
      " IGAN:0.7925 0.6815 0.6767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_mod(None, 5)\n",
    "torch.save(model.state_dict(), \"res18_5n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca9b91ef-2d83-417f-94a6-61006a820b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.6115 Accuracy: 0.6578 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.3548 0.5592 0.4342\n",
      " IGAN:0.8357 0.6880 0.7547\n",
      "\n",
      "val Loss: 0.6540 Accuracy: 0.6302 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6834 0.6783 0.6809\n",
      " IGAN:0.5575 0.5633 0.5603\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.5850 Accuracy: 0.6773 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4451 0.5840 0.5052\n",
      " IGAN:0.8137 0.7140 0.7606\n",
      "\n",
      "val Loss: 0.6459 Accuracy: 0.6338 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6244 0.7070 0.6631\n",
      " IGAN:0.6467 0.5577 0.5989\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.5738 Accuracy: 0.6933 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4740 0.6101 0.5335\n",
      " IGAN:0.8221 0.7269 0.7715\n",
      "\n",
      "val Loss: 0.6272 Accuracy: 0.6476 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8982 0.6384 0.7463\n",
      " IGAN:0.3053 0.6873 0.4228\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.5673 Accuracy: 0.6956 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4885 0.6108 0.5429\n",
      " IGAN:0.8172 0.7312 0.7718\n",
      "\n",
      "val Loss: 0.6803 Accuracy: 0.6120 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.4121 0.8304 0.5508\n",
      " IGAN:0.8851 0.5244 0.6586\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.5532 Accuracy: 0.7101 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5153 0.6331 0.5681\n",
      " IGAN:0.8246 0.7433 0.7819\n",
      "\n",
      "val Loss: 0.5753 Accuracy: 0.7034 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8178 0.7115 0.7610\n",
      " IGAN:0.5472 0.6875 0.6094\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.5406 Accuracy: 0.7230 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5428 0.6508 0.5919\n",
      " IGAN:0.8289 0.7553 0.7904\n",
      "\n",
      "val Loss: 0.6495 Accuracy: 0.6563 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5038 0.8354 0.6285\n",
      " IGAN:0.8645 0.5606 0.6802\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.5307 Accuracy: 0.7263 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5511 0.6546 0.5984\n",
      " IGAN:0.8292 0.7587 0.7924\n",
      "\n",
      "val Loss: 0.6260 Accuracy: 0.6846 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6068 0.7983 0.6895\n",
      " IGAN:0.7907 0.5956 0.6794\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.5078 Accuracy: 0.7435 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5736 0.6825 0.6233\n",
      " IGAN:0.8432 0.7710 0.8055\n",
      "\n",
      "val Loss: 0.5436 Accuracy: 0.7208 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8241 0.7281 0.7731\n",
      " IGAN:0.5798 0.7071 0.6371\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.5016 Accuracy: 0.7461 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5843 0.6836 0.6300\n",
      " IGAN:0.8412 0.7750 0.8067\n",
      "\n",
      "val Loss: 0.5613 Accuracy: 0.7215 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6570 0.8249 0.7315\n",
      " IGAN:0.8096 0.6336 0.7108\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.4977 Accuracy: 0.7534 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5954 0.6945 0.6411\n",
      " IGAN:0.8462 0.7807 0.8121\n",
      "\n",
      "val Loss: 0.5496 Accuracy: 0.7295 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7563 0.7708 0.7635\n",
      " IGAN:0.6930 0.6756 0.6842\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.5010 Accuracy: 0.7529 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5895 0.6961 0.6383\n",
      " IGAN:0.8488 0.7788 0.8123\n",
      "\n",
      "val Loss: 0.5292 Accuracy: 0.7302 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7513 0.7746 0.7628\n",
      " IGAN:0.7015 0.6738 0.6874\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.4895 Accuracy: 0.7583 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6032 0.7017 0.6487\n",
      " IGAN:0.8494 0.7847 0.8158\n",
      "\n",
      "val Loss: 0.5389 Accuracy: 0.7382 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7136 0.8103 0.7589\n",
      " IGAN:0.7719 0.6637 0.7137\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.4888 Accuracy: 0.7618 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6049 0.7087 0.6527\n",
      " IGAN:0.8540 0.7863 0.8187\n",
      "\n",
      "val Loss: 0.5423 Accuracy: 0.7353 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7148 0.8048 0.7572\n",
      " IGAN:0.7633 0.6622 0.7092\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.4842 Accuracy: 0.7614 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6046 0.7080 0.6523\n",
      " IGAN:0.8535 0.7861 0.8184\n",
      "\n",
      "val Loss: 0.5263 Accuracy: 0.7389 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7940 0.7633 0.7783\n",
      " IGAN:0.6638 0.7024 0.6825\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.4873 Accuracy: 0.7590 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6125 0.6989 0.6529\n",
      " IGAN:0.8451 0.7878 0.8154\n",
      "\n",
      "val Loss: 0.5411 Accuracy: 0.7331 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7073 0.8066 0.7537\n",
      " IGAN:0.7684 0.6579 0.7089\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.4890 Accuracy: 0.7568 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5978 0.7009 0.6453\n",
      " IGAN:0.8502 0.7825 0.8150\n",
      "\n",
      "val Loss: 0.5430 Accuracy: 0.7375 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7136 0.8091 0.7583\n",
      " IGAN:0.7702 0.6632 0.7127\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.4893 Accuracy: 0.7576 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6110 0.6966 0.6510\n",
      " IGAN:0.8437 0.7869 0.8143\n",
      "\n",
      "val Loss: 0.5297 Accuracy: 0.7302 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7312 0.7865 0.7578\n",
      " IGAN:0.7290 0.6651 0.6956\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.4864 Accuracy: 0.7629 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6070 0.7102 0.6546\n",
      " IGAN:0.8545 0.7873 0.8195\n",
      "\n",
      "val Loss: 0.5722 Accuracy: 0.7194 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6256 0.8484 0.7202\n",
      " IGAN:0.8473 0.6237 0.7185\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.4867 Accuracy: 0.7581 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6054 0.7003 0.6494\n",
      " IGAN:0.8478 0.7853 0.8154\n",
      "\n",
      "val Loss: 0.5271 Accuracy: 0.7404 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7839 0.7704 0.7771\n",
      " IGAN:0.6810 0.6977 0.6892\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.4852 Accuracy: 0.7648 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6096 0.7131 0.6573\n",
      " IGAN:0.8559 0.7887 0.8209\n",
      "\n",
      "val Loss: 0.5376 Accuracy: 0.7382 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7249 0.8025 0.7617\n",
      " IGAN:0.7564 0.6682 0.7096\n",
      "\n",
      "\n",
      "Training complete in 38m 30s\n",
      "Best val Acc: 0.7404 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8982 0.8484 0.7783\n",
      " IGAN:0.8851 0.7071 0.7185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_mod(None, 20)\n",
    "torch.save(model.state_dict(), \"res18_20n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7988579c-0828-4f37-8223-99bc15532d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VLSI\\anaconda3\\envs\\casper_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5522 Accuracy: 0.7082 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5200 0.6276 0.5688\n",
      " IGAN:0.8187 0.7439 0.7795\n",
      "\n",
      "val Loss: 0.5011 Accuracy: 0.7542 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8505 0.7547 0.7998\n",
      " IGAN:0.6226 0.7531 0.6817\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.5005 Accuracy: 0.7552 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6091 0.6923 0.6481\n",
      " IGAN:0.8410 0.7856 0.8123\n",
      "\n",
      "val Loss: 0.4555 Accuracy: 0.7941 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7814 0.8497 0.8141\n",
      " IGAN:0.8113 0.7311 0.7691\n",
      "\n",
      "\n",
      "Training complete in 3m 52s\n",
      "Best val Acc: 0.7941 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8505 0.8497 0.8141\n",
      " IGAN:0.8113 0.7531 0.7691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_mod(True, 2)\n",
    "torch.save(model.state_dict(), \"res18_2t.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d26c373-f360-4972-944e-5c03705b294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.5604 Accuracy: 0.7036 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5053 0.6225 0.5578\n",
      " IGAN:0.8200 0.7384 0.7770\n",
      "\n",
      "val Loss: 0.5208 Accuracy: 0.7302 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8467 0.7294 0.7837\n",
      " IGAN:0.5712 0.7319 0.6416\n",
      "\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.4965 Accuracy: 0.7577 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6160 0.6945 0.6529\n",
      " IGAN:0.8409 0.7885 0.8139\n",
      "\n",
      "val Loss: 0.5018 Accuracy: 0.7759 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7286 0.8618 0.7897\n",
      " IGAN:0.8405 0.6941 0.7603\n",
      "\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.4626 Accuracy: 0.7801 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6620 0.7210 0.6902\n",
      " IGAN:0.8495 0.8106 0.8296\n",
      "\n",
      "val Loss: 0.4681 Accuracy: 0.7955 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7852 0.8492 0.8159\n",
      " IGAN:0.8096 0.7341 0.7700\n",
      "\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.4417 Accuracy: 0.7942 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6852 0.7396 0.7114\n",
      " IGAN:0.8583 0.8228 0.8401\n",
      "\n",
      "val Loss: 0.4344 Accuracy: 0.8013 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8291 0.8271 0.8281\n",
      " IGAN:0.7633 0.7659 0.7646\n",
      "\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.4156 Accuracy: 0.8092 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7085 0.7598 0.7332\n",
      " IGAN:0.8684 0.8353 0.8515\n",
      "\n",
      "val Loss: 0.4719 Accuracy: 0.7999 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7601 0.8768 0.8143\n",
      " IGAN:0.8542 0.7228 0.7830\n",
      "\n",
      "\n",
      "Training complete in 9m 40s\n",
      "Best val Acc: 0.8013 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8467 0.8768 0.8281\n",
      " IGAN:0.8542 0.7659 0.7830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_mod(True, 5)\n",
    "torch.save(model.state_dict(), \"res18_5t.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9813fb5a-1bd5-4c8f-a9c7-8c2712e49d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.5542 Accuracy: 0.7165 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.5300 0.6414 0.5804\n",
      " IGAN:0.8260 0.7495 0.7859\n",
      "\n",
      "val Loss: 0.4957 Accuracy: 0.7679 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7337 0.8439 0.7849\n",
      " IGAN:0.8148 0.6914 0.7480\n",
      "\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.4923 Accuracy: 0.7631 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6269 0.7012 0.6620\n",
      " IGAN:0.8431 0.7937 0.8177\n",
      "\n",
      "val Loss: 0.5286 Accuracy: 0.7650 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6658 0.9014 0.7659\n",
      " IGAN:0.9005 0.6637 0.7642\n",
      "\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.4597 Accuracy: 0.7839 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6630 0.7286 0.6942\n",
      " IGAN:0.8549 0.8120 0.8329\n",
      "\n",
      "val Loss: 0.4387 Accuracy: 0.7948 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7676 0.8618 0.8120\n",
      " IGAN:0.8319 0.7239 0.7741\n",
      "\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.4357 Accuracy: 0.8014 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.6942 0.7504 0.7213\n",
      " IGAN:0.8644 0.8280 0.8458\n",
      "\n",
      "val Loss: 0.4357 Accuracy: 0.8013 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7977 0.8489 0.8225\n",
      " IGAN:0.8062 0.7448 0.7743\n",
      "\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.4127 Accuracy: 0.8124 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7092 0.7664 0.7367\n",
      " IGAN:0.8730 0.8364 0.8543\n",
      "\n",
      "val Loss: 0.4762 Accuracy: 0.7621 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.9083 0.7393 0.8151\n",
      " IGAN:0.5626 0.8180 0.6667\n",
      "\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.3881 Accuracy: 0.8290 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7395 0.7857 0.7619\n",
      " IGAN:0.8815 0.8521 0.8666\n",
      "\n",
      "val Loss: 0.4379 Accuracy: 0.7970 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8580 0.8035 0.8299\n",
      " IGAN:0.7136 0.7864 0.7482\n",
      "\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.3687 Accuracy: 0.8394 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7592 0.7972 0.7777\n",
      " IGAN:0.8865 0.8624 0.8743\n",
      "\n",
      "val Loss: 0.4564 Accuracy: 0.7912 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8279 0.8136 0.8207\n",
      " IGAN:0.7410 0.7592 0.7500\n",
      "\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.3237 Accuracy: 0.8643 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8009 0.8270 0.8137\n",
      " IGAN:0.9016 0.8852 0.8933\n",
      "\n",
      "val Loss: 0.4918 Accuracy: 0.7890 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7475 0.8686 0.8035\n",
      " IGAN:0.8456 0.7104 0.7721\n",
      "\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.3190 Accuracy: 0.8635 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7943 0.8297 0.8116\n",
      " IGAN:0.9042 0.8821 0.8930\n",
      "\n",
      "val Loss: 0.4608 Accuracy: 0.8042 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7902 0.8593 0.8233\n",
      " IGAN:0.8233 0.7419 0.7805\n",
      "\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.3189 Accuracy: 0.8666 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7983 0.8341 0.8158\n",
      " IGAN:0.9067 0.8844 0.8954\n",
      "\n",
      "val Loss: 0.4620 Accuracy: 0.7991 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7726 0.8650 0.8162\n",
      " IGAN:0.8353 0.7290 0.7786\n",
      "\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.2978 Accuracy: 0.8803 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8225 0.8492 0.8356\n",
      " IGAN:0.9142 0.8976 0.9059\n",
      "\n",
      "val Loss: 0.4525 Accuracy: 0.7919 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8530 0.7998 0.8255\n",
      " IGAN:0.7084 0.7792 0.7421\n",
      "\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.2958 Accuracy: 0.8808 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8222 0.8507 0.8362\n",
      " IGAN:0.9152 0.8976 0.9063\n",
      "\n",
      "val Loss: 0.4841 Accuracy: 0.7999 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7601 0.8768 0.8143\n",
      " IGAN:0.8542 0.7228 0.7830\n",
      "\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.2963 Accuracy: 0.8763 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8113 0.8479 0.8292\n",
      " IGAN:0.9145 0.8919 0.9031\n",
      "\n",
      "val Loss: 0.4492 Accuracy: 0.7999 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8229 0.8291 0.8260\n",
      " IGAN:0.7684 0.7606 0.7645\n",
      "\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.2944 Accuracy: 0.8763 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8113 0.8479 0.8292\n",
      " IGAN:0.9145 0.8919 0.9031\n",
      "\n",
      "val Loss: 0.4640 Accuracy: 0.8028 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7852 0.8609 0.8213\n",
      " IGAN:0.8268 0.7381 0.7799\n",
      "\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.2901 Accuracy: 0.8797 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8220 0.8481 0.8349\n",
      " IGAN:0.9135 0.8973 0.9054\n",
      "\n",
      "val Loss: 0.4503 Accuracy: 0.7977 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8090 0.8353 0.8220\n",
      " IGAN:0.7822 0.7500 0.7657\n",
      "\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.2893 Accuracy: 0.8823 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8192 0.8565 0.8374\n",
      " IGAN:0.9194 0.8964 0.9078\n",
      "\n",
      "val Loss: 0.4623 Accuracy: 0.7991 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8065 0.8392 0.8225\n",
      " IGAN:0.7890 0.7492 0.7686\n",
      "\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.2919 Accuracy: 0.8819 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8222 0.8532 0.8374\n",
      " IGAN:0.9169 0.8978 0.9072\n",
      "\n",
      "val Loss: 0.4631 Accuracy: 0.7933 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8028 0.8331 0.8177\n",
      " IGAN:0.7804 0.7435 0.7615\n",
      "\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.2914 Accuracy: 0.8772 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8170 0.8459 0.8312\n",
      " IGAN:0.9126 0.8946 0.9035\n",
      "\n",
      "val Loss: 0.4666 Accuracy: 0.7933 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8744 0.7900 0.8301\n",
      " IGAN:0.6827 0.7992 0.7364\n",
      "\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.2862 Accuracy: 0.8801 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8156 0.8538 0.8343\n",
      " IGAN:0.9180 0.8945 0.9061\n",
      "\n",
      "val Loss: 0.4928 Accuracy: 0.7970 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7688 0.8644 0.8138\n",
      " IGAN:0.8353 0.7258 0.7767\n",
      "\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.2932 Accuracy: 0.8809 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.8201 0.8524 0.8360\n",
      " IGAN:0.9166 0.8966 0.9065\n",
      "\n",
      "val Loss: 0.5182 Accuracy: 0.7883 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.7161 0.8962 0.7961\n",
      " IGAN:0.8868 0.6958 0.7798\n",
      "\n",
      "\n",
      "Training complete in 38m 33s\n",
      "Best val Acc: 0.8042 \n",
      "     Recall Precision F1_score\n",
      " MGN: 0.9083 0.9014 0.8301\n",
      " IGAN:0.9005 0.8180 0.7830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_mod(True, 20)\n",
    "torch.save(model.state_dict(), \"res18_20t.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af72f494-3ba6-4c2b-875e-c452b6927de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Finetuning the convnet ####\n",
    "# # Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "# model = models.resnet18(weights=True)\n",
    "# # print(model)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# # Here the size of each output sample is set to 2.\n",
    "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "# model.fc = nn.Linear(num_ftrs, 2)\n",
    "# model = model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # Observe that all parameters are being optimized\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# # StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # Learning rate scheduling should be applied after optimizerâ€™s update\n",
    "# # e.g., you should write your code this way:\n",
    "# # for epoch in range(100):\n",
    "# #     train(...)\n",
    "# #     validate(...)\n",
    "# #     scheduler.step()\n",
    "\n",
    "# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "# model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=2)\n",
    "# # torch.save(model.state_dict(), \"res18_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba409239-7576-4f31-8649-6d04276654a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### ConvNet as fixed feature extractor ####\n",
    "# # Here, we need to freeze all the network except the final layer.\n",
    "# # We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
    "# model_conv = torchvision.models.resnet18(weights=True)\n",
    "# for param in model_conv.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# num_ftrs = model_conv.fc.in_features\n",
    "# model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# model_conv = model_conv.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Observe that only parameters of final layer are being optimized as\n",
    "# # opposed to before.\n",
    "# optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "# model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "#                          exp_lr_scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4bd954e-d2a8-49b7-bf2d-bab280cadc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v2 = models.resnet18(weights=True)\n",
    "# num_ftrs = model_v2.fc.in_features\n",
    "# model_v2.fc = nn.Linear(num_ftrs, 2)\n",
    "# model_v2 = model_v2.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model_v2.parameters(), lr=0.001)\n",
    "# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "# model_v2 = train_model(model_v2, criterion, optimizer, step_lr_scheduler, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e2510301-f706-4be7-8781-df33fc7bd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_conv_v2 = torchvision.models.resnet18(weights=True)\n",
    "# for param in model_conv.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Parameters of newly constructed modules have requires_grad=True by default\n",
    "# num_ftrs = model_conv_v2.fc.in_features\n",
    "# model_conv_v2.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# model_conv_v2 = model_conv_v2.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Observe that only parameters of final layer are being optimized as\n",
    "# # opposed to before.\n",
    "# optimizer_conv = optim.SGD(model_conv_v2.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "# model_conv_v2 = train_model(model_conv_v2, criterion, optimizer_conv,\n",
    "#                          exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3401af48-127e-42c5-8602-2a7f1cdcaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v3 = models.resnet18(weights=False)\n",
    "# num_ftrs = model_v3.fc.in_features\n",
    "# model_v3.fc = nn.Linear(num_ftrs, 2)\n",
    "# model_v3 = model_v3.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model_v3.parameters(), lr=0.001)\n",
    "# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "# model_v3 = train_model(model_v3, criterion, optimizer, step_lr_scheduler, num_epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063cac16-d7df-4562-80a5-f3c1839bc1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef173139-84b6-4110-92b7-e8940f6e78a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casper_env",
   "language": "python",
   "name": "casper_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
